# Analyzing Historical History Dissertations: Cleaning the Data Again

```{r load-data}
library(dplyr)
library(stringr)
library(ggplot2)
library(reshape2)
library(knitr)
library(foreach)
opts_chunk$set(fig.width = 11, height = 7.75)
theme_set(theme_gray(base_size = 12))
source("load.r")
source("load2.r")
```

After a posts about the length of dissertations about history university by university and for the American academy as a whole, along with a map of where history dissertations have been written, this post will be much less interesting. In this post I want to write about some decisions that I've made to further clean and tidy the data, and the consequent revisions to earlier visualizations. I'm writing about this process because I have conceived of this series of posts as being not just a presentation of my findings about history dissertations, but a set of reflections on the process of data analysis as performed by a historian. I hope this series will be pedagogically useful. Certainly no one ever taught me how to do this kind of data analysis in a history department, and it's not that hard to find scientists complaining that no one ever taught them how to do this kind of work. So I hope this series of posts and the [accompanying code](https://github.com/lmullen/dissertations-data) is one [resource](http://programminghistorian.org/) [among](http://geospatialhistorian.wordpress.com/) [many](http://software-carpentry.org/), and in particular that it will be useful as a guide to the many steps in digging through a mid- to large-sized data set.

First, what do I mean by cleaning and tidying data? By cleaning data I mean changing the values of the data to make them more useful. For example, I have already removed some values from the data set that don't meet any definition of a history definition. Cleaning might also mean performing an operation like standardizing the name of a university, or joining all the fields that hold paragraphs for an abstract into one field. By tidying data I mean what [Hadley Wickham](http://had.co.nz/) means in this fantastic [journal article](http://vita.had.co.nz/papers/tidy-data.pdf) and [talk](http://vimeo.com/33727555), namely, changing the structure of data so that "each variable is a column, each observation is a row, and each type of observational unit is a table." To put it a different way, tidying data is akin to [normalizing the data](http://en.wikipedia.org/wiki/Database_normalization); cleaning the data is akin to proofreading the data.

So why do I need to clean and tidy the data after five posts? One possible model of how data analysis should proceed is that you first clean the data, then analyze. Another possible model is that you first set up the basic structure of the analysis, then clean the data to get the results that you want. In practice, learning from data is a process that iterates between analysis and cleaning. The process is iterative because you have to analyze the data before you know how the data must be cleaned and tidied, and you have to clean and tidy the data to make certain kinds of analysis available.

These are the kinds of tidying and cleaning that can happen at this stage.  

First, [mapping the dissertations](http://lincolnmullen.com/blog/analyzing-historical-history-dissertations-location/) made it obvious that the ProQuest data set contains very incomplete information for dissertations written outside North America. We may as well throw away those observations, since they are too incomplete to tell us anything useful. The data set also contains 4,608 dissertations from Canada. Looking at the quality of the data recorded for those Canadian dissertations, it seems that they are worth keeping. The deciding point for me is that the [AHA Directory of History Dissertations](https://secure.historians.org/pubs/dissertations/index.cfm) also includes Canadian dissertations.

Second, looking closely at the list of universities shows that there are some, such as the "Yale University, School of Forestry and Environmental Studies" which represent the occasional dissertation that might be about history, but is probably so far afield from the norm of a dissertation in history department that these may as well be excluded. Most of these will be dropped anyway when we filter the dissertations by subject.

Now we have a more difficult decision to make, since we have to decide what counts as a dissertation in history. There is a strong argument to be made that the best definition is a dissertation written in a history department. Unfortunately, since only `r round(100 * nrow(filter(h_diss2, !is.na(department)))/nrow(h_diss2), digits = 2)` percent of the dissertations in this data set identify their department, it is impossible to use that definition. But there are intellectual justifications for a more capacious definition. Certainly in my own field of American religious history, many if not most of the dissertations are written by people in religious studies departments, divinity schools, Judaic Studies departments, and the like. Economic history, particularly of a quantitative bent, has mostly moved to economics departments (though history of capitalism is making a roaring comeback in history departments). So I have no problem with using the ProQuest subject headings to study a broader definition of what a history dissertation is.

The sticking point for me is whether to include dissertations with the subject "Education, History of" as dissertations in history. The argument that such dissertations are usually written in schools of education rather than colleges of arts and sciences, are therefore held to different norms and so should be excluded from this study is persuasive to me. But we can also test the hypothesis that they are held to different norms.

Here is a chart of the page lengths of history of education dissertations vs all other kinds of history dissertations.

```{r history-of-education-vs-general}
ggplot() +
  geom_smooth(data = filter(h_diss, subject1 != "Education, History of."),
              aes(x = year, y = pages),
              color = "blue") +
  geom_smooth(data = filter(h_diss, subject1 == "Education, History of."),
              aes(x = year, y = pages),
              color = "red") +
  xlim(1945, 2012) +
  ggtitle("History dissertations (blue) vs history of education dissertations (red)")
```

There is a very wide divergence between the history of education and the other history dissertations, so I've decided to reverse my earlier decision and exclude them from the data set.

There is no such divergence for history of religion dissertations, so they can stay.

```{r history-of-religion-vs-general}
ggplot() +
  geom_smooth(data = filter(h_diss, subject1 != "Religion, History of."),
              aes(x = year, y = pages),
              color = "blue") +
  geom_smooth(data = filter(h_diss, subject1 == "Religion, History of."),
              aes(x = year, y = pages),
              color = "red") +
  xlim(1945, 2012) +
  xlab(NULL) +
  ggtitle("History dissertations (blue) vs history of religion dissertations (red)")
```

History of science has a bizarre trajectory compared to every other kind of history. (Historians of science, any ideas what is going on here?) But even though historians of science are often in different departments, they can stay in the data set. 

```{r history-of-science-vs-general}
ggplot() +
  geom_smooth(data = filter(h_diss, subject1 != "History of Science."),
              aes(x = year, y = pages),
              color = "blue") +
  geom_smooth(data = filter(h_diss, subject1 == "History of Science."),
              aes(x = year, y = pages),
              color = "red") +
  xlim(1945, 2012) +
  xlab(NULL) +
  ggtitle("Page lengths of history dissertations (blue) vs history of religion dissertations (red)")
```

History of economics diverges from general history (though not as sharply as history of education). I'm betting that's because such dissertations are more likely to use quantitative methods, so they can stay.

```{r history-of-economics-vs-general}
ggplot() +
  geom_smooth(data = filter(h_diss, subject1 != "Economics, History."),
              aes(x = year, y = pages),
              color = "blue") +
  geom_smooth(data = filter(h_diss, subject1 == "Economics, History."),
              aes(x = year, y = pages),
              color = "red") +
  xlim(1945, 2012) +
  xlab(NULL) +
  ggtitle("Page lengths of history dissertations (blue) vs history of economics dissertations (red)")
```

Biograpy also seems close to the profession in general.

```{r biography-vs-general}
ggplot() +
  geom_smooth(data = filter(h_diss, subject1 != "Biography."),
              aes(x = year, y = pages),
              color = "blue") +
  geom_smooth(data = filter(h_diss, subject1 == "Biography."),
              aes(x = year, y = pages),
              color = "red") +
  xlim(1945, 2012) +
  xlab(NULL) +
  ggtitle("Page lengths of history dissertations (blue) vs 'biography' dissertations (red)")
```

As a last step, I'm dropping all universities with fewer than five dissertations that meet all these criteria. Looking through these universities, many of their dissertations seem like false positives, so this cut-off should clean up problems in the long tail.

Making these changes to the data set gives us fewer dissertations: `r nrow(h_diss)` dissertations before, `r nrow(h_diss2)` after cleaning, which is `r nrow(h_diss) - nrow(h_diss2)` fewer dissertations. It's a messy process, but then the data is messy. Keep that in mind the next time you're impressed by a slick visualization.

* * * * * * * * * * *

Now that the data is more thoroughly cleaned, I have redone some of the more significant visualizations from the earlier posts. 

```{r define-scales}
# Some standard scales for chart labels
short_scale <- scale_x_continuous(breaks = seq(1950, 2010, 10),
                                  labels = seq(1950, 2010, 10),
                                  limits = c(1945, 2012))

page_scale <- function(min_pages, max_pages, increment) {
  scale <- scale_y_continuous(breaks = seq(min_pages, max_pages, increment),
                              labels = seq(min_pages, max_pages, increment),
                              limits = c(min_pages, max_pages))
  return(scale)
}
```

First, the number of dissertations per year.

```{r number-of-dissertations-per-year-2}
ggplot(h_diss2 %.%
         group_by(year) %.%
         summarise(count = length(id)),
       aes(x = year, y = count)) +
  geom_point() +
  geom_line() +
  ggtitle("Number of dissertations about history per year, 1945-2012") +
  short_scale +
  xlab(NULL) +
  ylab("Dissertations")
```

Second, the mean and median page counts of history dissertations. These are slightly higher after cleaning the data more thoroughly.

```{r calculate-average-pages-2}
average_pages <- h_diss2 %.%
  group_by(year) %.%
  summarise(
    mean = round(mean(pages, na.rm = TRUE)),
    median = median(pages, na.rm = TRUE)) %.%
  arrange(year)
  
average_pages_melted <- average_pages %.%
   melt(id = "year")
```

```{r pages-mean-median-2}
ggplot(average_pages_melted) +
  geom_line(aes(x = year, y = value, color = variable)) +
  short_scale +
  page_scale(275, 400,25) +
  labs(color = NULL) +
  ylab("Pages") +
  xlab(NULL) +
  ggtitle("Mean and Median Length of History Dissertations, 1945-2012")
```

Third, a map of the locations where history dissertations were written.

```{r}
university_count <- read.csv("location/universities-geocoded-2.csv")
```

<style>
#map {
  height: 500px;
  width: 800px;
  margin-top: 20px;
  margin-bottom: 20px;
  border: 1px solid gray;
}

#map img {
  border:0;
  -webkit-box-shadow: none;
  box-shadow: none;
}

.mycluster {
  width: 40px;
  background-color: lightcoral;
  text-align: center;
  font-size: 14px;
}
</style>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script>
$("head").append('<link rel="stylesheet" href="http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.css" />');

$("head").append('<link rel="stylesheet" href="/downloads/historical-dissertations/location/MarkerCluster.Default.css" />');
</script>

<script src="http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.js"></script>
<link rel="stylesheet" href="/downloads/historical-dissertations/location/MarkerCluster.css" />
<script src="/downloads/historical-dissertations/location/leaflet.markercluster-src.js"></script>
<script src="/downloads/historical-dissertations/location/leaflet.geocsv.js"></script>

<div id="map"></div>

<script>
var map = L.map('map');
var osmUrl='http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png';
var osmAttrib='Map data (c) OpenStreetMap contributors';
var osm = new L.TileLayer(osmUrl, {attribution: osmAttrib});  	

// start the map in the center of the United States
map.setView(new L.LatLng(39.8, -95), 4);
map.addLayer(osm);

var markers = new L.MarkerClusterGroup({
  iconCreateFunction: function (cluster) {
    var markers = cluster.getAllChildMarkers();
    var n = 0;
    for (var i = 0; i < markers.length; i++) {
      n += +markers[i].feature.properties["count"];
    }
    return L.divIcon({ html: n, className: 'mycluster', iconSize: L.point(50, 20) });
  },
});

$.get('/downloads/historical-dissertations/location/universities-geocoded-2.csv', function(csvContents) {
  var geoLayer = L.geoCsv(csvContents, {
    titles: ["","university","count","lon","lat"],
    firstLineTitles: true, 
    fieldSeparator: ',',
    latitudeTitle: 'lat',
    longitudeTitle: 'lon',
    onEachFeature: function (feature, layer) {
      var popup = '';
      popup += "<strong>" + feature.properties["university"] + "</strong>";
      popup += "<br/>";
      popup += "Dissertations about history: "
      popup += feature.properties["count"] + ".";
      layer.bindPopup(popup);
    }
  });
  markers.addLayer(geoLayer);
  map.addLayer(markers);
});
</script>

Finally, a redo of all the page counts by university. (Because nothing makes a post popular like giving every historian in North America a little blue dot of their own to look for.)

```{r create-pngs-by-university}
for (uni_name in university_count$university[1:179]) {
  fname <- str_c("pages-2-", 
                tolower(str_replace_all(uni_name, ' ', '-')),
                "png")
  png(filename = str_c("figure/", fname),
      width = 800, height = 600)
  plot <- ggplot(data = filter(h_diss2, str_detect(university, uni_name)),
                 aes(x = year, y = pages)) +
    geom_jitter(color = "cornflowerblue", alpha = 0.75) +
    geom_smooth(color = "darkblue") +
    geom_smooth(data = h_diss2, aes(x = year, y = pages), color = "red") +
    short_scale +
    page_scale(0, 1000, 100) +
    ggtitle(str_c("Length of history dissertations, profession (red) vs ",
                  uni_name, " (blue)")) +
    xlab(NULL) +
    ylab("Pages")
  print(plot)
  dev.off()
# }
```

```{r list-image-links}
for (uni_name in university_count$university) {
  fname <- str_c("pages-2-", 
                tolower(str_replace_all(uni_name, ' ', '-')),
                "png")
  cat("\n")
  cat(str_c(uni_name, "\n"))
  cat(str_c("{% img /downloads/historical-dissertations/", fname, " %}\n"))
}
```